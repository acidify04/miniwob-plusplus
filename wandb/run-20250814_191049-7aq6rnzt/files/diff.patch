diff --git a/train_custom.py b/train_custom.py
index 3a808ef..4186aa3 100644
--- a/train_custom.py
+++ b/train_custom.py
@@ -2,7 +2,9 @@ import gymnasium as gym
 import numpy as np
 from gymnasium import spaces
 from miniwob.action import ActionTypes
-import custom_registry
+#import custom_registry
+import wandb
+from wandb.integration.sb3 import WandbCallback
 
 from stable_baselines3 import PPO
 from stable_baselines3.common.env_util import make_vec_env
@@ -55,6 +57,17 @@ class MiniWoBClickImageEnv(gym.Env):
     def close(self):
         self.env.close()
 
+wandb.init(
+    project="miniwob-click",   # W&B 프로젝트 이름
+    config={                  # 하이퍼파라미터 기록
+        "policy_type": "CnnPolicy",
+        "total_timesteps": 10000,
+        "env_name": "MiniWoBClickImageEnv"
+    },
+    sync_tensorboard=True,     # tensorboard 로그도 같이 동기화
+    monitor_gym=True,          # gym 환경 모니터링
+    save_code=True             # 코드도 자동 저장
+)
 
 # 벡터화된 환경 생성
 env = make_vec_env(MiniWoBClickImageEnv, n_envs=1)
@@ -62,13 +75,20 @@ env = make_vec_env(MiniWoBClickImageEnv, n_envs=1)
 # (H, W, C) → (C, H, W) 변환
 env = VecTransposeImage(env)
 
-# # CNN Policy로 학습
-# model = PPO("CnnPolicy", env, verbose=1, tensorboard_log="./ppo_wob_tensorboard/")
-# model.learn(total_timesteps=10000)
-# model.save("click_model_cnn")
-
-# env = make_vec_env(MiniWoBClickImageEnv, n_envs=256)
-# env = VecTransposeImage(env)
+# CNN Policy로 학습
+model = PPO("CnnPolicy", env, verbose=1)
+model.learn(
+    total_timesteps=10000,
+    callback=WandbCallback(
+        gradient_save_freq=100,
+        model_save_path=f"models/{wandb.run.id}", # 학습된 모델도 W&B에 업로드
+        verbose=2
+    )
+)
+model.save("click_model_cnn")
+
+env = make_vec_env(MiniWoBClickImageEnv, n_envs=256)
+env = VecTransposeImage(env)
 
 model = PPO.load("click_model_cnn", env=env)
 
